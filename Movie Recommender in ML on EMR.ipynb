{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast predictive model-building with Apache Spark ML, DataFrames and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This article serves as a brief introduction to anyone interested in building predictive models with the Spark.ML library by walking through an example of building a simple recommendation engine. Whilst Spark's machine learning libraries are not as mature as single node libraries such as the excellent scikit-learn, each new release brings a raft of additional features that increasingly make it a realistic option for developing and deploying predictive models in production environments, and at scale. Spark MLlib has been around for quite a while, but a newer library, Spark.ML is now the focus of most new development (according the [this JIRA](https://issues.apache.org/jira/browse/SPARK-12626)), and  in the last few releases (1.4 - 1.6), many of the features that were previously only available in Scala/Java, have being ported to Python.  \n",
    "\n",
    "What ML offers over MLlib is tight integration with DataFrames, SparkSQL and the concept of Data Pipelines, designed to ease the process of chaining together complex data wrangling steps. I'm not going to go into the details here, they're explained at length [elsewhere](https://spark.apache.org/docs/latest/ml-guide.html), but I belive what these buy you is simplification and more automation of some of the more time consuming tasks of predictive modelling---data manipulation, feature engineering, hyperparameter tuning and model deployment. Spark DataFrames also benefit from optimisation of the execution plan via [Catalyst](https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html) that should make them [faster](http://www.adsquare.com/comparing-performance-of-spark-dataframes-api-to-spark-rdd/) and more space efficient compared to standard RDDs, especially in [Python](http://0x0fff.com/spark-dataframes-are-faster-arent-they/) where RDDs incur additional overhead. Since DataFrames and Pipelines were inspired by similar concepts in Python and R, the syntax should feel very familiar to Data Analyts/Scientists coming from those languages. \n",
    "\n",
    "In this Jupyter notebook I'm going to showcase some of the features of Spark.ML by walking through the development steps of a movie recommender based on [MovieLens](http://grouplens.org/datasets/movielens/), a commonly used dataset for testing recommenders that contains millions of user ratings of popular movies. Although small samples of MovieLens are often used for pedagogic purposes, I'm going use the full, up-to-date (as of Jan 2016) dataset that contains 22 million ratings of 33,000 movies made by 242,000 users to further underline the benefits why it's worth considering a scalable platform like Spark where data volumes or throughput is non-trivial. Whilst this particular dataset is not genuinely massive, it's still too large to execute comfortably on my laptop, so instead I'm going to run it on a small cluster deployed on Amazon Web Services that is quick and inexpensive to set up, costing about the same as a decent cup of coffee for a few hours of experimentation. A really handy feature is that I can still continue to develop my workflow in the Jupyter notebook in my browser as I might do in a stand-alone environment, and thus benefit from things like integrated code, documentation and data visualiazion all in one document, whilst all of the heavy lifting takes place in the cloud.\n",
    "\n",
    "The result is a workflow that is straightforward to set-up, code that is concise but readable, opportunities to explore data interactively and automate some of the more tedious aspects of model building, and a solution that scales out for deployment in large-scale environments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use an AWS cluster to process the data. The Spark distribution provides a pre-written script to be run from the command line that will provision a cluster of EC2 instances and install Spark running in stand-alone mode. However, in this instance, I'm using Amazon's managed hadoop service Elastic Map Reduce (EMR) that I've set up through the AWS Console in my browser, which walks me through the options available and then installs the neccessary software automatically, running atop Hadoop and Yarn ([see here](https://blogs.aws.amazon.com/bigdata/post/Tx6J5RM20WPG5V/Building-a-Recommendation-Engine-with-Spark-ML-on-Amazon-EMR-using-Zeppelin) for how). By default, EMR picks up the latest release of Spark, which is 1.6. Most of the code below requires at least versions 1.4 or 1.5 to run. \n",
    "\n",
    "I've set it up my cluster with 4 worker nodes and a master node that uses m3.xlarge nodes by default, which means 4 virtual CPUs, 15Gb of RAM per node. Now, the cost of provisioning a cluster on demand is around \\$ 0.266 an hour per node, which for a decent-sized cluster can soon mount up. So instead, I'm using spot instance pricing, which at the time of execution, was around \\$ 0.04 - \\$ 0.05 per hour per node. EMR also incurs a fixed charge of around \\$ 0.07 per instance per hour, and there is a small charge for data storage on S3. Finally I've installed Jupyter notebook on the master node so I can execute code interactively through the notebook in my browswer - see [here](http://blog.insightdatalabs.com/jupyter-on-apache-spark-step-by-step/) for how). Of course most of my code devlopment and data exploration was done locally on my laptop with a small data sample because I didn't want to rack up uneccessary AWS charges. However, once my code was ready to run on the full dataset, the only coding change required to run on the cluster was to point the load program to the larger datasets on S3 rather than my sample on local storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest version of the MovieLens data is formatted as csv files, and comes with a header row of named columns. There is no built-in function in Spark to load csv files directly into a DataFrame like there is in Pandas. One can load it into a conventional RDD with sc.textFile() and extract the fields in the conventional way with the map(lambda line: line.split(',') pattern, and then do the type conversions, convert it to a DataFrame, rename the resulting columns,and filter out the first line containing the column headers...and so on. So I find it more convenient to use the third party [csv package](https://github.com/databricks/spark-csv) from Databricks that will acomplish all of this in one step. The option 'inferschema' should cast the columns to the correct data type by scanning the first few rows of the file.\n",
    "\n",
    "The MovieLens dataset contains four files in total, but I'm only going to need two of them here. 'Ratings' contains the 22 million ratings (from 0 to 5) with integer keys to identify the user who provided the rating and the identity of the movie they rated. 'Movies' is a lookup table that maps the movie integer id in 'Ratings' to the full text name of the movie title, and a list of movie genres it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "sqlContext = HiveContext(sc)\n",
    "ratings = sqlContext.read \\\n",
    "    .format(\"com.databricks.spark.csv\") \\\n",
    "    .options(header = True, delimiter=',') \\\n",
    "    .load('s3n://sg-ml-latest/ratings.csv', inferschema = True)\n",
    "\n",
    "movies = sqlContext.read \\\n",
    "    .format(\"com.databricks.spark.csv\") \\\n",
    "    .options(header = True, delimiter=',') \\\n",
    "    .load('s3n://sg-ml-latest/movies.csv',  inferschema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    135|   3.0|1278471458|\n",
      "|     1|   1347|   4.0|1278471439|\n",
      "|     1|   1441|   4.0|1278471475|\n",
      "|     1|   2080|   3.0|1278471407|\n",
      "|     1|   2827|   3.0|1278471579|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22775244"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33869"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I dive in to building models, I'm going to take a brief exploratory look at the data. DataFrames and SparkSQL provide a glut of new convenience functions that allow data transformations such as datetime functions, window functions and basic descriptive statistics. There is a DataFrames API that  exposes these convenience functions as method calls in what is a SQL-like DSL, or alternatively one can to just pass a complete SQL or Hive expression as a string to the SQL function. I'll (unashamedly) alternate between both styles as I go along. Let's start by looking at the vintage of the ratings within each year, and the spread of those rating scores. The 'timestamp' field is in Unix time, so first I'm going to convert it into a more human-readable date and rename it 'ratingDate':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|         ratingDate|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|    135|   3.0|2010-07-07 02:57:38|\n",
      "|     1|   1347|   4.0|2010-07-07 02:57:19|\n",
      "|     1|   1441|   4.0|2010-07-07 02:57:55|\n",
      "|     1|   2080|   3.0|2010-07-07 02:56:47|\n",
      "|     1|   2827|   3.0|2010-07-07 02:59:39|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert a unixtimestamp to a readable date/time\n",
    "ratings_trans = ratings.select(ratings.userId, \n",
    "                         ratings.movieId,\n",
    "                         ratings.rating, \n",
    "                         pyspark.sql.functions.from_unixtime(ratings.timestamp).alias('ratingDate'))\n",
    "ratings_trans.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the number of ratings generated in each year. This time I want to chart the pattern, so I'm going to take the query result set and bring it back to the driver program and store it in a local Pandas dataframe with toPandas() so I can chart it using matplotlib and display it in this notebook. It seems there is a fairly even spread of ratings from 1996-2015 so I would expect a reasonable representation from movies released across that 20 year period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feafb161dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAF1CAYAAADm2uMAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feafb161290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import seaborn\n",
    "ratings_trans.groupBy(pyspark.sql.functions.year(ratings_trans.ratingDate)) \\\n",
    "    .count() \\\n",
    "    .toPandas() \\\n",
    "    .plot.bar(x='year(ratingDate)')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can get a quick breakdown of the ratings field with describe().It seems the lowest rating that can be given is half a point, not zero as I'd previously thought, and the maximum is five:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|          22775244|\n",
      "|   mean| 3.525978184909896|\n",
      "| stddev|1.0610787423393457|\n",
      "|    min|               0.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.describe('rating').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many ratings each movie has attracted. The movieId is not very informative on its own, so I'll need to join it to the movies lookup table in order to see the titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+--------------------+--------------------+\n",
      "|movieId|count|movieId|               title|              genres|\n",
      "+-------+-----+-------+--------------------+--------------------+\n",
      "|     31|11247|     31|Dangerous Minds (...|               Drama|\n",
      "|    231|35484|    231|Dumb & Dumber (Du...|    Adventure|Comedy|\n",
      "|    431|10118|    431|Carlito's Way (1993)|         Crime|Drama|\n",
      "|    631| 2552|    631|All Dogs Go to He...|Adventure|Animati...|\n",
      "|    831|  226|    831|    Stonewall (1995)|               Drama|\n",
      "+-------+-----+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_counts = ratings.groupBy(ratings.movieId) \\\n",
    "    .count() \\\n",
    "    .join(movies, ratings.movieId == movies.movieId) \\\n",
    "    \n",
    "rating_counts.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So, the average number of ratings per move is 683, but the spread is quite wide---some attract tens of thousands and others as few as a single rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             count|\n",
      "+-------+------------------+\n",
      "|  count|             33336|\n",
      "|   mean|  683.202663786897|\n",
      "| stddev|3148.7155091046634|\n",
      "|    min|                 1|\n",
      "|    max|             80913|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_counts.select('count').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequently rated movies are fairly obvious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+--------------------+--------------------+\n",
      "|movieId|count|movieId|               title|              genres|\n",
      "+-------+-----+-------+--------------------+--------------------+\n",
      "|    356|80913|    356| Forrest Gump (1994)|Comedy|Drama|Roma...|\n",
      "|    296|78740|    296| Pulp Fiction (1994)|Comedy|Crime|Dram...|\n",
      "|    318|77367|    318|Shawshank Redempt...|         Crime|Drama|\n",
      "|    593|75973|    593|Silence of the La...|Crime|Horror|Thri...|\n",
      "|    480|69401|    480|Jurassic Park (1993)|Action|Adventure|...|\n",
      "+-------+-----+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_counts.sort('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the DataFrame in the opposite direction reveals the least popular movies that have only been rated once. \n",
    "Movies with so few ratings can prove problematic to the recommender - we can't say much about the quality of the movie or who it is appropriate for based on a single rating, and it will also introduce a subtle bug into our test sets (see later).\n",
    "So I will be filtering out these unpopular movies from my working datasets in due course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+--------------------+------------------+\n",
      "|movieId|count|movieId|               title|            genres|\n",
      "+-------+-----+-------+--------------------+------------------+\n",
      "|  48235|    1|  48235|Flight from Death...|       Documentary|\n",
      "|  27235|    1|  27235|Shrink Is In, The...|    Comedy|Romance|\n",
      "|  72235|    1|  72235|Between the Devil...|             Drama|\n",
      "| 102035|    1| 102035| Holding, The (2011)|   Horror|Thriller|\n",
      "|  77435|    1|  77435|This Is the Army ...|Comedy|Musical|War|\n",
      "+-------+-----+-------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_counts.sort('count', ascending=True).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at how many ratings each user has submitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             count|\n",
      "+-------+------------------+\n",
      "|  count|            246829|\n",
      "|   mean| 92.27134574948649|\n",
      "| stddev|193.05029790942856|\n",
      "|    min|                 1|\n",
      "|    max|              9281|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_counts = ratings.groupBy(ratings.userId).count()\n",
    "user_counts.select('count').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean is 92 reviews, but this is influenced by a few enthusiasts who rate thousands of movies - the distribution is very positively skewed so most users rate far less than the average. There is no explicit median() function, but I can use the percentile function from Hive to do the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|lower_q|median|upper_q|\n",
      "+-------+------+-------+\n",
      "|   15.0|  29.0|   89.0|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_counts.registerTempTable('user_counts')\n",
    "sqlContext.sql(\"\"\"\n",
    "    select percentile(count, 0.25) as lower_q,\n",
    "    percentile(count, 0.5) as median, \n",
    "    percentile(count, 0.75) as upper_q\n",
    "    from user_counts\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the first recommender model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to start building models. In order to do this I'm going to create a test/hold-out dataset for evaluating the quality of my final model at the end of the process by spliting the data into two parts with randomSplit(). But first,\n",
    "I'm going to filter out movies and users that have provided very low numbers of ratings. I might be inclined to do this for reasons of model robustness, but the more practical reason I'm doing here is an implementation detail - the job will fail if I don't. The reason is due to the random allocation of observations to the training and test datasets. If I have ratings of particular movies or users that get allocated to the test set that, because of their low numbers, don't have a corresponding example in the training set, then the model doesn't know how to calculate a prediction for them and instead returns a Nan value. Consequently, when RegressionEvalutor attempts to calculate the RMSE across the test data, if it discovers a Nan in the model predictions, it also will return Nan as the result. As we will see in the next section, RegressionEvaluator is also used as part of the hyperparameter tuning process to compare various models in the cross-validation step, which also involves splitting the train dataset into multiple folds for model building and validation, so this process will also fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings before filter applied: 22775244\n",
      "ratings after filter applied: 22500271\n"
     ]
    }
   ],
   "source": [
    "ratings.registerTempTable('ratings')\n",
    "filtered_ratings = sqlContext.sql(\"\"\"\n",
    "    select\n",
    "    a.*\n",
    "    from ratings a \n",
    "    inner join (select movieId from ratings group by movieId having count(*) > 10 ) b\n",
    "    on a.movieId = b.movieId\n",
    "    inner join (select userId from ratings group by userId having count(*) > 10) c\n",
    "    on a.userId = c.userId\n",
    "\"\"\")\n",
    "\n",
    "print('ratings before filter applied:', ratings.count())\n",
    "print('ratings after filter applied:', filtered_ratings.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = filtered_ratings.randomSplit([0.7,0.3])\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only appropriate recommendation algorithm in this scenario that is built into Spark is Alternating Least Squares which implements factorisation of the User/Item matrix. I need to specify which columns represent the rating, user, and and movie identifier. There are some model hyperparameters that can be set in the call to ALS, but I will leave them at their defaults for now and come back to them in the next section. Calling fit() will return a model fitted with the training dataset I pass to it. The wall clock time of this fit produre on c.15 million ratings was around 2 minutes on my EMR cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(userCol = 'userId', itemCol = 'movieId', ratingCol = 'rating')\n",
    "model1 = als.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calling model.transform() on the trained model and this time passing it the test data will generate predictions for the previously unseen observations. The resulting column is called 'prediction' and we can easily compare it to the the rating the user actually gave to check how good the model predictions are. For the first observation, the model  overestimates the true user rating by 1.46, the second by 0.35, and so on:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+--------------------+\n",
      "|userId|movieId|rating| timestamp|prediction|               error|\n",
      "+------+-------+------+----------+----------+--------------------+\n",
      "|  1636|     31|   1.0|1085698669| 2.4686809|  1.4686808586120605|\n",
      "| 19436|     31|   3.0|1121817600| 3.3585715| 0.35857152938842773|\n",
      "| 24636|     31|   5.0| 884344250| 3.4005303| -1.5994696617126465|\n",
      "| 28236|     31|   3.0|1081396536|  3.313393| 0.31339311599731445|\n",
      "| 31236|     31|   4.0| 837955631|  3.815868|-0.18413209915161133|\n",
      "+------+-------+------+----------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions= model1.transform(test)\n",
    "predictions.withColumn('error', predictions.prediction - predictions.rating).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Finding the best model through hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first model used the default settings, but now I want to find the best peforming model by adjusting the parameters of the algorithm, such as the rank (i.e. number of latent factors to extract), and the regularization penalty. This can be done by trial and error, but more systematically by building a parameter grid, which will allow me to specify a range of parameter setttings for multiple hyperparameters, and then exhaustively test all possible combinations. \n",
    "\n",
    "I also need to specify an evaluation metric to summarise the prediction errors across the test dataset as a whole that will allow comparison between the numerous models I'm about to generate. There are different kinds of metrics used for evaluation recommendation quality, but the only relevant ones that are currently implemented in ML are those that are used to evaluate standard regression problems, so here I'm using Root Mean Squared Error (RMSE). \n",
    "\n",
    "Finally, I'm using cross validation with 5 folds, and even though my range for each hyperparameter has been set small in this example, the process will still generate a lot of candidate models and be fairly computationally expensive. However the total runtime was around 1 hour on my EMR cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import *\n",
    "als =  ALS(userCol = 'userId', itemCol = 'movieId', ratingCol = 'rating')\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(als.rank, [10, 20, 40, 60]) \\\n",
    "    .build()\n",
    "    \n",
    "    \n",
    "cv = CrossValidator() \\\n",
    "    .setEstimator(als) \\\n",
    "    .setEstimatorParamMaps(param_grid) \\\n",
    "    .setEvaluator(RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\",  metricName=\"rmse\")) \\\n",
    "    .setNumFolds(5)\n",
    "    \n",
    "cv_model = cv.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cv_model object retains the details of the best performing model on the cross validation process. So finally, I finish by calculating the error of the best performing model on the test set that hitherto, has not been used in model selection and should provide an unbaised estimate of real-word performance on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7811422347004146"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\",  metricName=\"rmse\")\n",
    "evaluator.evaluate(cv_model.bestModel.transform(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What would you recommend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By way of a more concrete example, let's pick a user at random and analyse what recommendations the algorithm would've made for them, based on how they've rated other movies. The code returns the top 20 predictions tailored to this user from the test dataset based on the learned ALS model. The highest recommendationare are Shawshank, Godfather 2, Raiders of the Lost Ark etc, which correlates closely with their actual ratings, so intial prognosis is that the recommendations are not too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+--------------------+------+----------+\n",
      "|userId|movieId|               title|              genres|rating|prediction|\n",
      "+------+-------+--------------------+--------------------+------+----------+\n",
      "|    23|    318|Shawshank Redempt...|         Crime|Drama|   4.0| 4.5498276|\n",
      "|    23|   1221|Godfather: Part I...|         Crime|Drama|   5.0|   4.47567|\n",
      "|    23|   1193|One Flew Over the...|               Drama|   5.0|  4.392229|\n",
      "|    23|   1198|Raiders of the Lo...|    Action|Adventure|   5.0|  4.353747|\n",
      "|    23|   1207|To Kill a Mocking...|               Drama|   5.0| 4.3274226|\n",
      "|    23|   1234|   Sting, The (1973)|        Comedy|Crime|   5.0| 4.3210397|\n",
      "|    23|   1233|Boot, Das (Boat, ...|    Action|Drama|War|   5.0| 4.3163137|\n",
      "|    23|    720|Wallace & Gromit:...|Adventure|Animati...|   3.0| 4.2668924|\n",
      "|    23|   4973|Amelie (Fabuleux ...|      Comedy|Romance|   4.0|  4.264877|\n",
      "|    23|    903|      Vertigo (1958)|Drama|Mystery|Rom...|   4.0| 4.2496524|\n",
      "|    23|   2028|Saving Private Ry...|    Action|Drama|War|   5.0| 4.2115235|\n",
      "|    23|   1247|Graduate, The (1967)|Comedy|Drama|Romance|   5.0| 4.1694174|\n",
      "|    23|   3198|     Papillon (1973)|         Crime|Drama|   5.0|  4.134769|\n",
      "|    23|   1263|Deer Hunter, The ...|           Drama|War|   5.0|  4.132662|\n",
      "|    23|   1242|        Glory (1989)|           Drama|War|   4.0|  4.131014|\n",
      "|    23|   2762|Sixth Sense, The ...|Drama|Horror|Mystery|   4.0| 4.1304564|\n",
      "|    23|    110|   Braveheart (1995)|    Action|Drama|War|   4.0| 4.0820355|\n",
      "|    23|   3095|Grapes of Wrath, ...|               Drama|   4.0|  4.078151|\n",
      "|    23|   1292|  Being There (1979)|        Comedy|Drama|   5.0|  4.052619|\n",
      "|    23|   4011|       Snatch (2000)|Comedy|Crime|Thri...|   4.0|  4.044347|\n",
      "+------+-------+--------------------+--------------------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_recommmendations = cv_model.bestModel.transform(test)\n",
    "example_recommendations = cv_recommmendations.filter(cv_recommmendations.userId==23) \\\n",
    "    .join(movies, cv_recommmendations.movieId == movies.movieId) \\\n",
    "    .select('userId', cv_recommmendations.movieId, 'title', 'genres', 'rating', 'prediction') \\\n",
    "    .orderBy('prediction', ascending=False) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally (just for fun) let's look at the recommender's predictions based on movies the user genuinely hasn't rated yet, and then cast a subjective eye over what would be recommended if we were to deploy the algorithm today. For this example I'm going back the the original ratings dataset (before I split it into 2) to filter out all of the user's previously rated movies from the result set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_seen = filtered_ratings.filter(filtered_ratings.userId==23).select('movieId')\n",
    "allmovies = movies.select('movieId')\n",
    "movies_ids_to_be_seen =  allmovies.subtract(movies_seen)\n",
    "\n",
    "movies_ids_to_be_seen.registerTempTable('movie_ids_to_be_seen')\n",
    "movies.registerTempTable('movies')\n",
    "                        \n",
    "movies_to_be_seen = sqlContext.sql(\"\"\"\n",
    "    select a.movieId, 23 as userId, b.title, b.genres\n",
    "    from movie_ids_to_be_seen a \n",
    "    inner join movies b \n",
    "    on a.movieId = b.movieId\"\"\")\n",
    "\n",
    "movies_rated =cv_model.bestModel.transform(movies_to_be_seen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the results are...unexpected! Fascinating to see lots of documentaries and stand-up comedy acts, but at some point I'm going to have to delve deeper into the user's existing ratings profile to try to work out why these predictions were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------------+--------------------+----------+\n",
      "|movieId|userId|               title|              genres|prediction|\n",
      "+-------+------+--------------------+--------------------+----------+\n",
      "| 100511|    23|House Is Black, T...|         Documentary| 4.7685204|\n",
      "|  94735|    23|Walking with Mons...|         Documentary| 4.6351557|\n",
      "|  69483|    23|Not on Your Life ...|        Comedy|Drama| 4.6293344|\n",
      "| 139100|    23|Once Brothers (2010)|         Documentary| 4.6274576|\n",
      "|  92498|    23|Dylan Moran Live:...|              Comedy| 4.6191936|\n",
      "| 116975|    23|Long Way Round (2...|Adventure|Documen...| 4.6186757|\n",
      "| 101850|    23|Death on the Stai...|   Crime|Documentary| 4.6130514|\n",
      "| 113474|    23|Autobiography of ...|               Drama| 4.6003656|\n",
      "|  88067|    23|Happiness Is a Wa...|    Animation|Comedy|  4.572539|\n",
      "| 118468|    23|Mei and the Kitte...|   Animation|Fantasy|  4.568615|\n",
      "|  96471|    23|Prime Suspect 3 (...| Crime|Drama|Mystery| 4.5386686|\n",
      "|  26941|    23|Pretty Village, P...|           Drama|War|  4.536244|\n",
      "| 141946|    23|         Meru (2015)|         Documentary| 4.5283847|\n",
      "|  72360|    23|Rocks (Das Rad) (...|Action|Animation|...| 4.5275383|\n",
      "| 147376|    23|Doctor Who: A Chr...|  (no genres listed)|  4.515356|\n",
      "| 130347|    23|Bill Hicks: Sane ...|              Comedy| 4.4978886|\n",
      "| 128099|    23|Jim Jefferies: BA...|              Comedy|  4.492242|\n",
      "| 136463|    23|Jim Gaffigan: Bey...|              Comedy|  4.483238|\n",
      "| 100553|    23|Frozen Planet (2011)|         Documentary| 4.4765873|\n",
      "|  77658|    23|       Cosmos (1980)|         Documentary| 4.4755664|\n",
      "+-------+------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_rated.orderBy('prediction', ascending = False).dropna().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've given a brief demonstration of model building in the new Spark ML API. I hope you'll agree that the resulting code is straightforward and familar in style to Data Analyts/Scientists who code in Python, R or SQL and, to some tastes, preferable to the approach taken by MLlib. Althought there are still weaknesses in the library in its current incarnation, some of these issues are likely to be addressed in the [next release]((https://issues.apache.org/jira/browse/SPARK-12626). I like that fact that I can integrate so many stages of the modelling lifecycle into one environment, using a language of my choice, and then deploy it at scale should I need to. The MovieLens dataset is a relatively clean and easy dataset to process, so complex data wrangling was not required in this case (and if it were it wouldn't make for easy reading), but the ML and SparkSQL API now contains dozens of convenience functions that make this often tedious process easier than it might be otherwise. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
